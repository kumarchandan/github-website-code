<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.e3ada421adb9e1d43f47.css" id="gatsby-global-css">:root{--reach-skip-nav:1}[data-reach-skip-nav-link]{border:0;clip:rect(0 0 0 0);height:1px;width:1px;margin:-1px;padding:0;overflow:hidden;position:absolute}[data-reach-skip-nav-link]:focus{padding:1rem;position:fixed;top:10px;left:10px;background:#fff;z-index:1;width:auto;height:auto;clip:auto}html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block}audio:not([controls]){display:none;height:0}progress{vertical-align:baseline}[hidden],template{display:none}a{background-color:transparent;-webkit-text-decoration-skip:objects}a:active,a:hover{outline-width:0}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:inherit;font-weight:bolder}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background-color:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}svg:not(:root){overflow:hidden}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}figure{margin:1em 40px}hr{box-sizing:content-box;height:0;overflow:visible}button,input,optgroup,select,textarea{font:inherit;margin:0}optgroup{font-weight:700}button,input{overflow:visible}button,select{text-transform:none}[type=reset],[type=submit],button,html [type=button]{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-cancel-button,[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-input-placeholder{color:inherit;opacity:.54}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{font:112.5%/1.45em georgia,serif;box-sizing:border-box;overflow-y:scroll}*,:after,:before{box-sizing:inherit}body{color:rgba(0,0,0,.8);font-size:18px;font-family:Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;word-wrap:break-word;-webkit-font-kerning:normal;font-kerning:normal;-ms-font-feature-settings:"kern","liga","clig","calt";font-feature-settings:"kern","liga","clig","calt"}img{max-width:100%;padding:0;margin:0 0 1.45rem}h1{font-size:2.25rem}h1,h2{padding:0;margin:0 0 1.45rem;color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:700;text-rendering:optimizeLegibility;line-height:1.1}h2{font-size:1.62671rem}h3{font-size:1.38316rem}h3,h4{padding:0;margin:0 0 1.45rem;color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:700;text-rendering:optimizeLegibility;line-height:1.1}h4{font-size:1rem}h5{font-size:.85028rem}h5,h6{padding:0;margin:0 0 1.45rem;color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:700;text-rendering:optimizeLegibility;line-height:1.1}h6{font-size:.78405rem}hgroup{padding:0;margin:0 0 1.45rem}ol,ul{padding:0;margin:0 0 1.45rem 1.45rem;list-style-position:outside;list-style-image:none}dd,dl,figure,p{padding:0;margin:0 0 1.45rem}pre{margin:0 0 1.45rem;font-size:.85rem;line-height:1.42;background:rgba(0,0,0,.04);border-radius:3px;overflow:auto;word-wrap:normal;padding:1.45rem}table{font-size:1rem;line-height:1.45rem;border-collapse:collapse;width:100%}fieldset,table{padding:0;margin:0 0 1.45rem}blockquote{padding:0;margin:0 1.45rem 1.45rem}form,iframe,noscript{padding:0;margin:0 0 1.45rem}hr{padding:0;margin:0 0 calc(1.45rem - 1px);background:rgba(0,0,0,.2);border:none;height:1px}address{padding:0;margin:0 0 1.45rem}b,dt,strong,th{font-weight:700}li{margin-bottom:.725rem}ol li,ul li{padding-left:0}li>ol,li>ul{margin-left:1.45rem;margin-bottom:.725rem;margin-top:.725rem}blockquote :last-child,li :last-child,p :last-child{margin-bottom:0}li>p{margin-bottom:.725rem}code,kbd,samp{font-size:.85rem;line-height:1.45rem}abbr,abbr[title],acronym{border-bottom:1px dotted rgba(0,0,0,.5);cursor:help}abbr[title]{text-decoration:none}td,th,thead{text-align:left}td,th{border-bottom:1px solid rgba(0,0,0,.12);font-feature-settings:"tnum";-moz-font-feature-settings:"tnum";-ms-font-feature-settings:"tnum";-webkit-font-feature-settings:"tnum";padding:.725rem .96667rem calc(.725rem - 1px)}td:first-child,th:first-child{padding-left:0}td:last-child,th:last-child{padding-right:0}code,tt{background-color:rgba(0,0,0,.04);border-radius:3px;font-family:SFMono-Regular,Consolas,Roboto Mono,Droid Sans Mono,Liberation Mono,Menlo,Courier,monospace;padding:.2em 0}pre code{background:none;line-height:1.42}code:after,code:before,tt:after,tt:before{letter-spacing:-.2em;content:" "}pre code:after,pre code:before,pre tt:after,pre tt:before{content:""}@media only screen and (max-width:480px){html{font-size:100%}}</style><meta name="generator" content="Gatsby 2.29.3"/><title data-react-helmet="true">LSTMs GRUs &amp; Attention Blocks | Chandan Kumar</title><link data-react-helmet="true" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&amp;display=swap"/><meta data-react-helmet="true" name="description" content="LSTMs The idea of LSTMs (Long Short-term Memory Networks) is closely related to the fact that we, humans, understand the context when we…"/><meta data-react-helmet="true" property="og:title" content="LSTMs GRUs &amp; Attention Blocks"/><meta data-react-helmet="true" property="og:description" content="LSTMs The idea of LSTMs (Long Short-term Memory Networks) is closely related to the fact that we, humans, understand the context when we…"/><meta data-react-helmet="true" property="og:type" content="website"/><meta data-react-helmet="true" name="twitter:creator" content="Chandan Kumar"/><meta data-react-helmet="true" name="twitter:title" content="LSTMs GRUs &amp; Attention Blocks"/><meta data-react-helmet="true" name="twitter:description" content="LSTMs The idea of LSTMs (Long Short-term Memory Networks) is closely related to the fact that we, humans, understand the context when we…"/><meta data-react-helmet="true" name="twitter:card" content="summary"/><link rel="icon" href="/favicon-32x32.png?v=4fa8a8e72c4df7eedcc92731fa138956" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><meta name="theme-color" content="#663399"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=4fa8a8e72c4df7eedcc92731fa138956"/><link as="script" rel="preload" href="/webpack-runtime-9f2c574a289b8d10f777.js"/><link as="script" rel="preload" href="/styles-e9d24b1846c7d6eb9685.js"/><link as="script" rel="preload" href="/framework-305b3707783ccc9d7ca6.js"/><link as="script" rel="preload" href="/app-b19935da96722da2d371.js"/><link as="script" rel="preload" href="/commons-a58d11507ffed914d508.js"/><link as="script" rel="preload" href="/857e319847ef3f25a9e8913b82e7502ac13a96b7-142c170fa3e97008bf86.js"/><link as="script" rel="preload" href="/799b9e28ec84f08939ab3af68c08e0b6efc8bad3-4a4db2880bdad04bced8.js"/><link as="script" rel="preload" href="/component---node-modules-gatsby-theme-blog-core-src-templates-post-query-js-187bada29997ee279035.js"/><link as="fetch" rel="preload" href="/page-data/blog/natural-language-processing/LSTMs-GRUs-&amp;-Attention-Blocks/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/2744905544.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/3090755652.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/386998304.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/sq/d/764694655.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><script>(function() { try {
  var mode = localStorage.getItem('theme-ui-color-mode');
  if (!mode) return
  document.body.classList.add('theme-ui-' + mode);
} catch (e) {} })();</script><div id="___gatsby"><style data-emotion-css="zk5xvy">body{--theme-ui-colors-text:#282c35;--theme-ui-colors-background:#fff;--theme-ui-colors-primary:#007acc;--theme-ui-colors-secondary:#1B1F23;--theme-ui-colors-muted:hsla(0,0%,0%,0.2);--theme-ui-colors-highlight:rgba(255,229,100,0.2);--theme-ui-colors-heading:#282c35;--theme-ui-colors-prism-background:#011627;--theme-ui-colors-prism-comment:#809393;--theme-ui-colors-prism-string:#addb67;--theme-ui-colors-prism-var:#d6deeb;--theme-ui-colors-prism-number:#f78c6c;--theme-ui-colors-prism-constant:#82aaff;--theme-ui-colors-prism-punctuation:#c792ea;--theme-ui-colors-prism-className:#ffc98b;--theme-ui-colors-prism-tag:#ffa7c4;--theme-ui-colors-prism-boolean:#ff5874;--theme-ui-colors-prism-property:#80cbc4;--theme-ui-colors-prism-namespace:#b2ccd6;--theme-ui-colors-prism-highlight:hsla(207,95%,15%,1);color:var(--theme-ui-colors-text,#282c35);background-color:var(--theme-ui-colors-background,#fff);}body.theme-ui-dark{--theme-ui-colors-text:rgba(255,255,255,0.86);--theme-ui-colors-background:#232129;--theme-ui-colors-primary:#D9BAE8;--theme-ui-colors-secondary:rgba(255,255,255,0.86);--theme-ui-colors-muted:hsla(0,0%,100%,0.2);--theme-ui-colors-highlight:#663399;--theme-ui-colors-heading:#fff;}</style><style data-emotion-css="8ir1vi">*{box-sizing:border-box;}body{margin:0;font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",sans-serif;}</style><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><style data-emotion-css="ocpejr">.css-ocpejr{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",sans-serif;}</style><div class="css-ocpejr"><header><style data-emotion-css="o7eq5i">.css-o7eq5i{color:var(--theme-ui-colors-primary,#007acc);}</style><a class="css-o7eq5i" href="#reach-skip-nav" data-reach-skip-link="" data-reach-skip-nav-link="">Skip to content</a><style data-emotion-css="1ufxd81">.css-1ufxd81{max-width:672px;margin-left:auto;margin-right:auto;padding-left:16px;padding-right:16px;padding-top:32px;}</style><div class="css-1ufxd81"><style data-emotion-css="4c94nt">.css-4c94nt{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:32px;}</style><div class="css-4c94nt"><style data-emotion-css="1qd1r5f">.css-1qd1r5f{margin-top:0;margin-bottom:0;}</style><p class="css-1qd1r5f"><style data-emotion-css="1febbns">.css-1febbns{box-shadow:none;-webkit-text-decoration:none;text-decoration:none;color:var(--theme-ui-colors-primary,#007acc);}</style><style data-emotion-css="1a7e4c0">.css-1a7e4c0{color:var(--theme-ui-colors-primary,#007acc);box-shadow:none;-webkit-text-decoration:none;text-decoration:none;color:var(--theme-ui-colors-primary,#007acc);}</style><a class="css-1a7e4c0" href="/">Chandan Kumar</a></p></div></div></header><div id="reach-skip-nav" data-reach-skip-nav-content=""></div><div><style data-emotion-css="1in33uw">.css-1in33uw{max-width:672px;margin-left:auto;margin-right:auto;padding-left:16px;padding-right:16px;padding-top:32px;padding-bottom:32px;}</style><div class="css-1in33uw"><main><article><header><h1 class="css-0">LSTMs GRUs &amp; Attention Blocks</h1><style data-emotion-css="1h1xv8c">.css-1h1xv8c{font-size:14px;margin-top:-16px;margin-bottom:16px;}</style><style data-emotion-css="dv5tmu">.css-dv5tmu{font-size:14px;margin-top:-16px;margin-bottom:16px;}.css-dv5tmu code{font-size:inherit;}</style><p class="css-dv5tmu">December 03, 2020</p></header><section><style data-emotion-css="h7w91b">.css-h7w91b{pointer-events:painted;}.css-h7w91b a{visibility:hidden;}.css-h7w91b:hover a{visibility:visible;}</style><h1 id="lstms" class="css-h7w91b"><style data-emotion-css="vvm4x1">.css-vvm4x1{margin-left:-20px;padding-right:4px;color:var(--theme-ui-colors-primary,#007acc);}</style><a href="#lstms" aria-label="[object Object]" class="css-vvm4x1"><svg viewBox="0 0 16 16" width="16" height="16" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><strong class="css-0">LSTMs</strong></h1><style data-emotion-css="1ek8oqb">.css-1ek8oqb code{font-size:inherit;}</style><p class="css-1ek8oqb">The idea of LSTMs (Long Short-term Memory Networks) is closely related to the fact that we, humans, understand the context when we talk. And, there is no way a traditional neural network can help in storing this context. So Recurrent neural networks (RNNs) were invented to tackle this problem. These are networks with a recurring nature that allows information to persist.</p><p class="css-1ek8oqb">A simple RNN looks like this:</p><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:885px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:59.710144927536234%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA90lEQVQoz52SW0/DMAyF9///Hg+IMpAYbOnW5u7EdpwVUngAAW0Rn/KSyzlHtrMrP+BSqoiOcK/OWBZh5t1vp+Va5eLizcNTYpZPzy2xFBGpDULRI0qdt/Mqsi7m9tDAqGHw2Wqrx15bMC4ZA4NLtun5S/735HZtQGdOKWByhL6AIcwEGHUcN8SNIZwj+uRzDGCsbhYZc+Tg0U3T60bNCVuq9y4EF/rLKTk8KdU93j2/HJRSRLTe7bk7FAv7ymHicFVHtd/vu65rltuj+qgeI8GATNzS+J02gj+JRQogjw5Z/vNJam/97eGYuMiKmBfISBYSL9PKeQOL0be+PghzrQAAAABJRU5ErkJggg==&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="1UOKamqFOlHJ2mkWJ1kL-RA.png" title="1UOKamqFOlHJ2mkWJ1kL-RA.png" src="/static/dcf51126fa4fac2ab2bc84ff323581da/efc66/1UOKamqFOlHJ2mkWJ1kL-RA.png" srcSet="/static/dcf51126fa4fac2ab2bc84ff323581da/e4d6b/1UOKamqFOlHJ2mkWJ1kL-RA.png 345w,/static/dcf51126fa4fac2ab2bc84ff323581da/1e043/1UOKamqFOlHJ2mkWJ1kL-RA.png 690w,/static/dcf51126fa4fac2ab2bc84ff323581da/efc66/1UOKamqFOlHJ2mkWJ1kL-RA.png 885w" sizes="(max-width: 885px) 100vw, 885px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">A Simple RNN</p><p class="css-1ek8oqb">It takes an input x and outputs ahidden state h. It also has another output which also goes as input to the RNN block. This way it has the ability to connect previous information to the current task. Though simple RNNs fail when it comes to understanding longer sequences of texts.</p><p class="css-1ek8oqb">LSTMs are a special kind of RNN. It covers up the shortcomings of a simple RNN which is good for a short sequence of information.</p><p class="css-1ek8oqb">LSTMs are capable of learning long-term dependencies. Its key part is - Cell state. The horizontal green line running in the below picture. It holds information on previous input sequences.</p><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1380px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:44.63768115942029%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsTAAALEwEAmpwYAAABGElEQVQoz41RSXLEIAz0/x+YY1ITr+OyMSBAC9gVYXuSHHJIVxdIQGujERGzGgge8KKb5gnSaSfvk+uH/nbRhxQiRWNXAMg5NyrezOZDfXfSDv3oo78EHt3QjfBynff1ZXSIqMKGmUspGibLTQKphoKFU7azz1Kx73v32bWP9jgOdVXYXJv8AoV8nmQETkDr06pbg2NZJmM3q7lu8Y8yixYQEN/eWymlfS6PcS7H/jGsSbiblsewhC0GH/IlljMzYmISQlIi8jQ6DbiZsK6gIecnkLprMBYEMwW50t1lb5tJEcFEuzi9Iy9asK4EXA13r5kzJU6Oo36Jc/fAaj9FGLVDVEPr/5uv7r7H1BARn1BDP4L/hzpXoi8KXgbFxe/tVQAAAABJRU5ErkJggg==&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="1YS1G3zRg-yB3KN1euR3HCA.png" title="1YS1G3zRg-yB3KN1euR3HCA.png" src="/static/3f5a4bcd9d179527f91de3781a1b922c/b1001/1YS1G3zRg-yB3KN1euR3HCA.png" srcSet="/static/3f5a4bcd9d179527f91de3781a1b922c/e4d6b/1YS1G3zRg-yB3KN1euR3HCA.png 345w,/static/3f5a4bcd9d179527f91de3781a1b922c/1e043/1YS1G3zRg-yB3KN1euR3HCA.png 690w,/static/3f5a4bcd9d179527f91de3781a1b922c/b1001/1YS1G3zRg-yB3KN1euR3HCA.png 1380w,/static/3f5a4bcd9d179527f91de3781a1b922c/10ab7/1YS1G3zRg-yB3KN1euR3HCA.png 1552w" sizes="(max-width: 1380px) 100vw, 1380px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">An LSTM Block</p><p class="css-1ek8oqb">Process of LSTMs can be understood in the following 4 steps:</p><p class="css-1ek8oqb"><strong class="css-0">Step 1</strong> - Throw away what’s not needed</p><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:680px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:69.85507246376812%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsTAAALEwEAmpwYAAACk0lEQVQoz0WSy0sVURzH76I2LqI2tWnXrkXSroVhQQRBEBGBCLWKguiFlSFFghXYkwTRuTNnnl7vla75wFITKwwXKYV6nTlnXnfmzONetdL6E/qdM0bwXfzm8Tnf7/mek0MmVUisWlSxqIwpwhFIIhEifOCPfKAqjg0SF+y0aNcGndqAneZkK1JJqgabSrAp+xsy/GrR/zCJZFA24MggiUFSMONf45yCY82k2tMOvbdb+fwF4QR5ayj7zIAsC4Ulhv16wY7/BYHl4pxKYmXFH7p2aux4w3j39dGP08rUpEwSRpKYBYHZTuBvzWWeEidFJoAtqjl1bdktdF4ev39xrPOS3taifv0uu3XZoshJ5RUXLTsiSfJLNs8fZ6TEYBwxuRA1RfML8qc5EbQasKps5qPebFF7HgvfbOHBLWT6EjPnvBVBYbTk1spuUvZrw9GvN9HmSLL1NlgzICpJpBVPmpo27rSKs3NqWyuyQtFOWWwrYTDEHnDSopsOeaDaoJuWPCbD4d2QSIz+FG6fV4aLSslAvd15b12C48hgBYdQg4KhHig25qLwkj9Gkhnk6W/j9cNi19UrL/teNO3TJ9/l/Z/iaihalMFQuEaoyrU9sCsRSgQcqmK4VTD65AtN984eLR7bVbpxWjApkIIZQGEZHCl8CY2E2anyEw6Zc/VHYbz8pHl/e3Pj85OHXx3ZoxXEfn9DqPiw51AncHW2PRUCgRkPgr2JWUPzC/q5xrGOQ++fHZy4ewA9ahf89f6KB20HOqE6v4bZlZRxoBAmGCQrEDEVlvyJrjPBzG46vxOP7kXlYr9TE1a9HDKrLCHUA54YPEEMk3FVw55sVkWrmq+EizMn3Nkcnm2wP+wYWhzpsepCxf0Lhm9ibrVS+2kAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="0ElVZHjrZqPa-v-iO.png" title="0ElVZHjrZqPa-v-iO.png" src="/static/a1be5d2e6839d3b13bb68649c21c23c7/c5bb3/0ElVZHjrZqPa-v-iO.png" srcSet="/static/a1be5d2e6839d3b13bb68649c21c23c7/e4d6b/0ElVZHjrZqPa-v-iO.png 345w,/static/a1be5d2e6839d3b13bb68649c21c23c7/c5bb3/0ElVZHjrZqPa-v-iO.png 680w" sizes="(max-width: 680px) 100vw, 680px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">Source: KnowYourMeme</p><p class="css-1ek8oqb">The incoming Cell state contains information about the whole input sequence up to that moment. The first task is to figure out what information to be thrown away from the Cell state. This decision is taken using a sigmoid layer called the <strong class="css-0">Forget gate</strong>. It looks at the incoming input and the hidden state and produces numbers between 0 and 1. Values reaching towards 0 will be the ones that should be forgotten.</p><p class="css-1ek8oqb"><strong class="css-0">Step 2</strong> - Compute and keep what’s needed</p><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1024px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:82.6086956521739%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAARABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAECBQME/8QAFwEBAQEBAAAAAAAAAAAAAAAAAQACA//aAAwDAQACEAMQAAABy+lJ57qgnn0Qbiv/xAAaEAEBAQEAAwAAAAAAAAAAAAABAgAREiEy/9oACAEBAAEFAmjUd1Si+Or2vRNXy7//xAAVEQEBAAAAAAAAAAAAAAAAAAAQAv/aAAgBAwEBPwEk/8QAFREBAQAAAAAAAAAAAAAAAAAAEAL/2gAIAQIBAT8BKP/EABcQAAMBAAAAAAAAAAAAAAAAAAABEAL/2gAIAQEABj8CM1VCP//EABwQAAICAgMAAAAAAAAAAAAAAAABETFBcRBRYf/aAAgBAQABPyGvMjlljLKBOh06EcSvRYDMODTQ/9oADAMBAAIAAwAAABCU8P8A/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAExEP/aAAgBAwEBPxBQeXT/xAAWEQEBAQAAAAAAAAAAAAAAAAAAATH/2gAIAQIBAT8QRuJj/8QAHBABAAIDAAMAAAAAAAAAAAAAAQARITGhcbHB/9oACAEBAAE/EFCA1NZmWICquSlXCWIaSVl1RvFR6a0M2DUvQ6wiok28pyHqcf7P/9k=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="0qWGCKriL7pvUauPF.jpg" title="0qWGCKriL7pvUauPF.jpg" src="/static/e7cc9d5555019c1fd011142f314d5354/72e01/0qWGCKriL7pvUauPF.jpg" srcSet="/static/e7cc9d5555019c1fd011142f314d5354/8d48c/0qWGCKriL7pvUauPF.jpg 345w,/static/e7cc9d5555019c1fd011142f314d5354/15ec7/0qWGCKriL7pvUauPF.jpg 690w,/static/e7cc9d5555019c1fd011142f314d5354/72e01/0qWGCKriL7pvUauPF.jpg 1024w" sizes="(max-width: 1024px) 100vw, 1024px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">Source: <a href="https://www.reddit.com/r/TheHobbitFaction/comments/9b4lmd/the_elves_are_here_to_honor_the_alliance_with_a/" class="css-o7eq5i">Reddit</a></p><p class="css-1ek8oqb">This is done by the part called the <strong class="css-0">Input gate</strong>.</p><p class="css-1ek8oqb">It has two parts, the first one is a Sigmoid layer and another is a tanh layer. Both of them figure out what information will be updated to the Cell state.</p><p class="css-1ek8oqb"><strong class="css-0">Step 3</strong> - Update the Cell State</p><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:620px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:75.07246376811594%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAABAABA//EABYBAQEBAAAAAAAAAAAAAAAAAAMAAv/aAAwDAQACEAMQAAABLjjm/KRWP//EABkQAQEBAAMAAAAAAAAAAAAAAAECAAMRIv/aAAgBAQABBQI7kOSsGa8wBTe//8QAFxEBAAMAAAAAAAAAAAAAAAAAAhARIf/aAAgBAwEBPwEk1sf/xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAgEBPwFWf//EABgQAAIDAAAAAAAAAAAAAAAAAAABECEx/9oACAEBAAY/AqFF4ao//8QAHBAAAgMAAwEAAAAAAAAAAAAAAREAITFBUYGh/9oACAEBAAE/ISpF4YSgKYeZKs+QPG2uMLetltAGf//aAAwDAQACAAMAAAAQO/8A/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQBBgf/aAAgBAwEBPxBycXL/xAAXEQADAQAAAAAAAAAAAAAAAAAAARFh/9oACAECAQE/EGmXT//EABwQAQEAAgIDAAAAAAAAAAAAAAERADEhUZGxwf/aAAgBAQABPxB1SwV8W8SAB8kVqawxlWt5fcerkgC+jATQCUcHvWLcDsz/2Q==&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="0o2I5WIsHgW4yd_t_.jpg" title="0o2I5WIsHgW4yd_t_.jpg" src="/static/a4d9f9a4e3b2b701ee61b3df5008f069/935bc/0o2I5WIsHgW4yd_t_.jpg" srcSet="/static/a4d9f9a4e3b2b701ee61b3df5008f069/8d48c/0o2I5WIsHgW4yd_t_.jpg 345w,/static/a4d9f9a4e3b2b701ee61b3df5008f069/935bc/0o2I5WIsHgW4yd_t_.jpg 620w" sizes="(max-width: 620px) 100vw, 620px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">Source: <a href="https://imgflip.com/i/1xbpmi" class="css-o7eq5i">Imgflip</a></p><p class="css-1ek8oqb">Now is the time to update the old Cell state to a new Cell state using the values calculated in the previous step.</p><p class="css-1ek8oqb"><strong class="css-0">Step 4</strong> - Compute what to output</p><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:640px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:75.07246376811594%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABAAD/8QAFAEBAAAAAAAAAAAAAAAAAAAAA//aAAwDAQACEAMQAAABCw2pqqDC3//EABsQAAICAwEAAAAAAAAAAAAAAAECERMAAyEi/9oACAEBAAEFAgSGmEvjC3fFa7ef/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAERIf/aAAgBAwEBPwGaY//EABYRAQEBAAAAAAAAAAAAAAAAAAASIf/aAAgBAgEBPwHUv//EAB4QAAIBAwUAAAAAAAAAAAAAAAARARIiMQIhUWGR/9oACAEBAAY/AkslVGjY5L5SFXnoumPD/8QAHBAAAwACAwEAAAAAAAAAAAAAAAERITFRYXGx/9oACAEBAAE/IaMr7IWK+g0KehGdmkzRO96PPg//2gAMAwEAAgADAAAAEIAf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAREA/9oACAEDAQE/EIuFlu//xAAXEQEBAQEAAAAAAAAAAAAAAAABABEh/9oACAECAQE/EDUs5l//xAAdEAEBAAMAAgMAAAAAAAAAAAABEQAhMUGhUWGB/9oACAEBAAE/EOKPHxndH3lk6Fpw2T3cUNgBRreGC3CjTu11jQkjYtvx6yRIOiLn5n//2Q==&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="0wXBpEo8MEFKfGGMh.jpg" title="0wXBpEo8MEFKfGGMh.jpg" src="/static/f86ec52db40d5b00ba00141d0be627e0/c08c5/0wXBpEo8MEFKfGGMh.jpg" srcSet="/static/f86ec52db40d5b00ba00141d0be627e0/8d48c/0wXBpEo8MEFKfGGMh.jpg 345w,/static/f86ec52db40d5b00ba00141d0be627e0/c08c5/0wXBpEo8MEFKfGGMh.jpg 640w" sizes="(max-width: 640px) 100vw, 640px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">Source: <a href="https://www.reddit.com/r/Texans/comments/j5u19z/looks_like_watching_the_games_is_back_on_the_menu/" class="css-o7eq5i">Reddit</a></p><p class="css-1ek8oqb">Run a sigmoid layer to decide which part of the new Cell state to output. This process happens at the <strong class="css-0">Output gate</strong>.</p><p class="css-1ek8oqb">Put the new Cell state through tanh and multiply it by the output of the sigmoid function, so that only selected parts are in the output.</p><h1 id="grus" class="css-h7w91b"><a href="#grus" aria-label="GRUs" class="css-vvm4x1"><svg viewBox="0 0 16 16" width="16" height="16" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>GRUs</h1><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1380px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:50.14492753623189%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAABFElEQVQoz4WS22oDIRBA8/9/17dQKG3a7Lrqul7nphZqtkmhJTTHUUQ8zDB6qDvMLCI8xgjl+GzYOjZjo3nSghhSWIPtvY9r9cZhzNZazjnlVDgnjHGeL2F0Mnp9eUvnKcZt0pONuv7mKgPA8KVKhODQUScSgkpqMRkLIDizoeA4/Ct/+4NeOzIoMwcXKtdR4fyu4poxSnBp1Hwn8w+ttkJ5jdbbVDKw0LoEhgqJnPGt1QcycMmSjqePefW1ydPzaywQiY6T5fq/3PpilfVa6+h9YWK1xILEJMljfZC5Nz0ZpRQV4iIjo0CVtr9hkQfyXvdn9gUSUhZMjJEva2DKfEeWG+OfjIZv2wYZL60mucb+ce7yBU9EQDzNPzJHAAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="1mkLsVOtT7E-J00DGFHY1vQ.png" title="1mkLsVOtT7E-J00DGFHY1vQ.png" src="/static/02b15e01168f0197b469365c65fb997d/b1001/1mkLsVOtT7E-J00DGFHY1vQ.png" srcSet="/static/02b15e01168f0197b469365c65fb997d/e4d6b/1mkLsVOtT7E-J00DGFHY1vQ.png 345w,/static/02b15e01168f0197b469365c65fb997d/1e043/1mkLsVOtT7E-J00DGFHY1vQ.png 690w,/static/02b15e01168f0197b469365c65fb997d/b1001/1mkLsVOtT7E-J00DGFHY1vQ.png 1380w,/static/02b15e01168f0197b469365c65fb997d/f4b34/1mkLsVOtT7E-J00DGFHY1vQ.png 1457w" sizes="(max-width: 1380px) 100vw, 1380px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">A GRU Block</p><p class="css-1ek8oqb">GRUs (Gated Recurrent Units) is the combination of both Peephole and Coupled Forget-Input LSTMs variants. You can read about these variants <a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" class="css-o7eq5i">here</a>.</p><p class="css-1ek8oqb">In its architecture, it combines the forget and input gate into a single <strong class="css-0">update gate</strong>. It also merges the cell state and hidden state, which is passed to both the gates as shown above in the picture. It works on the idea that more the information a network has, the better it will learn.</p><p class="css-1ek8oqb">In the normal LSTM, forgetting unnecessary information happens using the Forget gate, and adding new information is decided by the Input gate. Both the operation can be handled at once. The idea is that if you have set aside the information to be forgotten, the rest of the information is to be stored, so use that. From this Coupled Forget-Input gate, the input to the Input gate is inverse of the Forget gate. This idea is referred to as Yin Yang.</p><p class="css-1ek8oqb"><strong class="css-0">LSTMs vs GRUs</strong></p><p class="css-1ek8oqb">There are no research papers claiming that GRUs are better than LSTMs. Though people prefer GRU because it uses less number of neural network which leads to less number of parameters and faster training time.</p><h1 id="attention" class="css-h7w91b"><a href="#attention" aria-label="Attention" class="css-vvm4x1"><svg viewBox="0 0 16 16" width="16" height="16" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Attention</h1><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:599px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:66.66666666666666%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsTAAALEwEAmpwYAAADJElEQVQozwEZA+b8AFJDK1pKMmJQNmJPMaqlnsHFypyZk7CtqMbIzLi5ucvMy7q8vrW3uby8vL2/wZ2WjltHL0Y4ITEkEzEkFgBaSTJjUTlpWDxxXj6Ogm6bk4SXjnyTiHSck4OdlYB+eGx1a2WVjYWKhX+CfHhsYVZmUTdQPyg2KBU0JxcAX082aFc9cGBBemhGgGtIgWtIgm5LhHFNg3FKempFQjMjl3ZTj3JYTTktMiQaNSceaVQ9W0gwOiwXNyoYAGNSOW1cQHZmRYFtTIdzUoh1VIh4VYl5VYp7VoJzUEU4KZR7YKGBYW5ZSHtqV1pNPm1ZQ2RRNz4wGTksGQBlVTtxX0N7a0qFclCIdlOJeVWKelaLfFWLflWMfVVTRjaXdlyYd1qlg2mynoTy48Krk3NlUDZDNR46LRkAaFg+dGJFfm5Mh3ZTiHhVinpVjH1WjH9WjH9XkIFYWlBBZE08x4lwlG1XqZV8793AmH9jXUgxSzwkOy4aAGhYPnNjRn9vTYh3VIl5Vot7Vox9V41/V46AWJCCWWhaRjApJ3pgSIZhRTYkGci9o7ukhCcVDDgsHz0vGwBmVj1xYER9bUuGdlOJeVaLe1iLfVeNf1mNf1mPglpsWUE0JyJvXkmniWdHMyVaSTz+8M1rWUQaEhE6LyAAZVQ8cGBFfGxOhndUintXi3tYjX1YjX5Zj4FagXNRVkAwOSUZlYBpvqOCdF1LPicbybme28ypoI9wmoNhAFxNNWFONmVRN3BbP3hmR35uTYFxUIJxT4Z0UWtYQFQ/NEErH2tQPMmvioFoUT0mHIFtXOviwtXBmLSWbgBKNCJKMiBTOSRaPSlkRzBqUDagmZCkn5mlnpirpJ6loJyZlJCnoZ27saN3XEVMNStaQzbNwaTQxaOvk24AQiscTTYlWkEsXUItYkUvdFpDu7u8rrG0paeqvsDDqq2utba32tzelpSUTzouUT40Lx4Xl4dv0sepsJ18ADspHEIvIlhAL1c/K1k+K2VMOHRkVHloWXRlV6eWg6eXhVlOSUxJR0VDPzwxKk8+NyIZFFZLPMW2maqagDovQrClpOB8AAAAAElFTkSuQmCC&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="15ez14Ef72Nyp3MEpZEILmA.png" title="15ez14Ef72Nyp3MEpZEILmA.png" src="/static/15bcb809e5fe15d9c23f11ab733b2ac4/43142/15ez14Ef72Nyp3MEpZEILmA.png" srcSet="/static/15bcb809e5fe15d9c23f11ab733b2ac4/e4d6b/15ez14Ef72Nyp3MEpZEILmA.png 345w,/static/15bcb809e5fe15d9c23f11ab733b2ac4/43142/15ez14Ef72Nyp3MEpZEILmA.png 599w" sizes="(max-width: 599px) 100vw, 599px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">In NLP tasks such as sentiment analysis, we only need to focus on the final output, where LSTMs/GRUs perform well. Though there are NLP tasks like Language translation where every output matters and LSTMs/GRUs do not perform that great there.</p><p class="css-1ek8oqb">Attention mechanism comes to the rescue. It works with a set of encoders and decoders to handle the complexity of these tasks.</p><p class="css-1ek8oqb"><span class="gatsby-resp-image-wrapper" style="position:relative;display:block;margin-left:auto;margin-right:auto;max-width:1380px">
      <span class="gatsby-resp-image-background-image" style="padding-bottom:59.130434782608695%;position:relative;bottom:0;left:0;background-image:url(&#x27;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAAsTAAALEwEAmpwYAAABW0lEQVQoz22SyW7DMAxE/f+/2EsPBerEthaK1EIqQUd2m60hBMMW/UTOUFNrTZ/DzC79wswppevl6oPHPyxMkax3pG9/To+w7VFrxXvgEFNQUxc3yRL3zwFf7vx0w/AspRwFAwWpQjlucbWuJzdL5WyixLp4jTz41kZlkMCISFhQ1tRqq4GdoxUMeJIYkgvskVDOWkZrA8ZTRFBt9A+uay4SKYYYoBapdVuJEnZEeDT4qDnnDLL3jgTl4GkLyaNss9ptbB6pI16sndAnYEjFixd3Wud5+T67uWqBFbsfNz/1Fd6bb9A8OnQrFrpNnEoe5iGbKOU94Mi9eHse1Ug0PQwDtrjz4haIPW/z5tc1LMRxH0kdJGambXpzSdRIiOtYcLiYeN6kJjbMKejHl37O6ug9fByA8WBVrT5t0E8SkvxVzljl17D2L5DYVWacEnErzSAYAW1t19vGHWk/Pz21z0pdv2QAAAAASUVORK5CYII=&#x27;);background-size:cover;display:block"></span>
  <img class="gatsby-resp-image-image css-0" alt="1km_Vb_XouZ0BlWD5EGCI1A.png" title="1km_Vb_XouZ0BlWD5EGCI1A.png" src="/static/93430de56dd91fbe80afe60fc3bac89d/b1001/1km_Vb_XouZ0BlWD5EGCI1A.png" srcSet="/static/93430de56dd91fbe80afe60fc3bac89d/e4d6b/1km_Vb_XouZ0BlWD5EGCI1A.png 345w,/static/93430de56dd91fbe80afe60fc3bac89d/1e043/1km_Vb_XouZ0BlWD5EGCI1A.png 690w,/static/93430de56dd91fbe80afe60fc3bac89d/b1001/1km_Vb_XouZ0BlWD5EGCI1A.png 1380w,/static/93430de56dd91fbe80afe60fc3bac89d/80cfc/1km_Vb_XouZ0BlWD5EGCI1A.png 1844w" sizes="(max-width: 1380px) 100vw, 1380px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0" loading="lazy"/>
    </span></p><p class="css-1ek8oqb">Attention is all you need!</p><p class="css-1ek8oqb">It has a part called <strong class="css-0">context vector</strong> that enables the decoder to focus on certain parts of the input while it predicts the output. Each context vector is a weighted sum of the outputs (h1, h2, h3) of the encoders.</p><p class="css-1ek8oqb">To get the context vectors (c1, c2, c3), the Attention layer looks at all the values of h states and incoming values of s.</p><p class="css-1ek8oqb">More details on Attention will come in the next part. So stay tuned!</p></section></article></main><style data-emotion-css="1i8tjli">.css-1i8tjli{margin-top:32px;padding-top:16px;}</style><footer class="css-1i8tjli"><style data-emotion-css="1u77lb1">.css-1u77lb1{border-color:var(--theme-ui-colors-muted,hsla(0,0%,0%,0.2));}</style><hr class="css-1u77lb1"/><style data-emotion-css="j6r63x">.css-j6r63x{margin-bottom:32px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><style data-emotion-css="u5xevn">.css-u5xevn{box-sizing:border-box;margin:0;min-width:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-bottom:32px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><div class="css-u5xevn"><style data-emotion-css="1emx3y6">.css-1emx3y6{margin-right:8px;margin-bottom:0;width:48px;min-width:48px;border-radius:99999px;}</style><div class="css-1emx3y6 gatsby-image-wrapper" style="position:relative;overflow:hidden;display:inline-block;width:48px;height:48px"><img aria-hidden="true" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAACVklEQVQ4y62UvWsiURTFx8Ro1GiM+ZKIaK8pBa2t0tiIXcqUAStTioUIfhQpDKQT/wD/A7FKY8qQzk6ixMZGoo3x7J4Ld3YGV9hlVzjMe2/u/c25972nEQ6HcXl5iYuLC5yfn+P09BShUAgnJyc4Pj5GIBCA3+/H0dERvF4vPB4PDg8P4XK5cHBwAKfTif39fTgcDhiGAcMKOzs72wn0+Xw7gXt7e7+ACrMCCQsGgyaQ7qxAt9u9G6ggqzurQy2XQIruFEhtAQlRkI4JYCKfhOqcjgjTkgXwUwTq2FBHFJOZFIvFcH19LXMG0xkdsz0smzFcVyMmjGKglse+PT8/Y71eY7PZ4PPzE4VCQQLr9Tq+vr4Qj8dl/vT0BP7y+bzdJUH8CntQqVQkqFqtIpvNYjgcypyOG42GjBl/e3sr43a7vV2ydSfH4zFeX1/Nl8lkEoPBAKlUCrVaDd/f38jlclJBv98348wNoQhjk6PRKJbLJXq9nrygax4RDX58fBRXs9lMnolEQta5y7Ye8lhw566urqRHCmRfuZNaTrPZFNB8Ppdnp9PZLpfS88WdG41GeHt7M1+m02lZy2QyKJfLAuKa9vPm5kbiePVMIMti/zi5v7+XwG63i7u7O3x8fMic5bdaLRnTOctk6YvFQm6YrY/sn4pfenh4wHQ6xWq1wsvLizhiYKlUwvv7OyKRiMzpbjKZoFgs2kvXK6TXiYssnwdYy9B/FC3NuqvMs/WQyVYxQBMJ4prtWPzuqFjFJJW6UNku/Z9KE60i5K9BKk3+J4hdBv6nfgCuvESEgoE/JAAAAABJRU5ErkJggg==" alt="Chandan Kumar" style="position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;object-position:center;opacity:1;transition-delay:500ms"/><noscript><picture><source srcset="/static/4fa8a8e72c4df7eedcc92731fa138956/aff39/avatar.png 1x,
/static/4fa8a8e72c4df7eedcc92731fa138956/e5b88/avatar.png 1.5x,
/static/4fa8a8e72c4df7eedcc92731fa138956/88b72/avatar.png 2x" /><img loading="lazy" width="48" height="48" srcset="/static/4fa8a8e72c4df7eedcc92731fa138956/aff39/avatar.png 1x,
/static/4fa8a8e72c4df7eedcc92731fa138956/e5b88/avatar.png 1.5x,
/static/4fa8a8e72c4df7eedcc92731fa138956/88b72/avatar.png 2x" src="/static/4fa8a8e72c4df7eedcc92731fa138956/aff39/avatar.png" alt="Chandan Kumar" style="position:absolute;top:0;left:0;opacity:1;width:100%;height:100%;object-fit:cover;object-position:center"/></picture></noscript></div><div class="css-0">Thank you for reading!<!-- --> <br/>Words by <a href="/" class="css-o7eq5i">Chandan Kumar</a></div></div><style data-emotion-css="11r1i3o">.css-11r1i3o{-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;list-style:none;padding:0;}</style><style data-emotion-css="15qbtrw">.css-15qbtrw{box-sizing:border-box;margin:0;min-width:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;list-style:none;padding:0;}</style><ul class="css-15qbtrw"><li><a rel="prev" class="css-o7eq5i" href="/blog/100-days-of-deep-learning/day3-gradient-descent/">← <!-- -->Gradient Descent</a></li><li></li></ul></footer></div></div></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/blog/natural-language-processing/LSTMs-GRUs-&-Attention-Blocks/";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"polyfill":["/polyfill-64e392f65b32dbfbc7b7.js"],"app":["/app-b19935da96722da2d371.js"],"component---node-modules-gatsby-theme-blog-core-src-templates-post-query-js":["/component---node-modules-gatsby-theme-blog-core-src-templates-post-query-js-187bada29997ee279035.js"],"component---node-modules-gatsby-theme-blog-core-src-templates-posts-query-js":["/component---node-modules-gatsby-theme-blog-core-src-templates-posts-query-js-03b597eb4f465a417c6e.js"],"component---src-pages-404-js":["/component---src-pages-404-js-a0d4ada7e32bbb86c28b.js"],"component---src-pages-index-js":["/component---src-pages-index-js-196de454e6e7f4a83941.js"],"component---src-pages-page-2-js":["/component---src-pages-page-2-js-84c7cc9358a48c4e1f76.js"]};/*]]>*/</script><script src="/polyfill-64e392f65b32dbfbc7b7.js" nomodule=""></script><script src="/component---node-modules-gatsby-theme-blog-core-src-templates-post-query-js-187bada29997ee279035.js" async=""></script><script src="/799b9e28ec84f08939ab3af68c08e0b6efc8bad3-4a4db2880bdad04bced8.js" async=""></script><script src="/857e319847ef3f25a9e8913b82e7502ac13a96b7-142c170fa3e97008bf86.js" async=""></script><script src="/commons-a58d11507ffed914d508.js" async=""></script><script src="/app-b19935da96722da2d371.js" async=""></script><script src="/framework-305b3707783ccc9d7ca6.js" async=""></script><script src="/styles-e9d24b1846c7d6eb9685.js" async=""></script><script src="/webpack-runtime-9f2c574a289b8d10f777.js" async=""></script></body></html>